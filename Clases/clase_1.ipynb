{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5372f1e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sampling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mT\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_functions\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Audio\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sampling'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import soundfile as sf           \n",
    "import numpy as np               \n",
    "import matplotlib.pyplot as plt  \n",
    "from scipy.signal import welch   \n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as sps\n",
    "import librosa\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "from sampling import module_functions\n",
    "from IPython.display import Audio\n",
    "from IPython import display\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as Fu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbae06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_SAMPLE_DIR_AUD  = \"audio_data\"\n",
    "audio_path = os.path.join(_SAMPLE_DIR_AUD, \"sandy-beach.wav\")\n",
    "os.makedirs(_SAMPLE_DIR_AUD, exist_ok=True)\n",
    "\n",
    "_SAMPLE_DIR_IMG  = \"image_data\"\n",
    "img_path = os.path.join(_SAMPLE_DIR_IMG, \"set_up.png\")\n",
    "os.makedirs(_SAMPLE_DIR_IMG, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83b723a",
   "metadata": {},
   "source": [
    "# Procesamiento básico de imágenes y audio\n",
    "\n",
    "+ Nuestros dos sentidos más importantes son la <span style=\"color:red\">visión</span> y la <span style=\"color:red\">audición</span>.\n",
    "\n",
    "+ Curiosamente, muchas veces al explicar el procesamiento de audio, hacemos directa relaciòn con el procesamiento de <span style=\"color:red\">imágenes</span>.\n",
    "\n",
    "+ En la vida real, ambos sentidos funcionan de manera combinada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b9198",
   "metadata": {},
   "source": [
    "## Observemos la siguiente escena de un paisaje de playa de arena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d15a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "plt.figure(figsize=[6, 6])\n",
    "plt.imshow(image)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b3258c",
   "metadata": {},
   "source": [
    "## Qué sensación les da la escena visual? \n",
    "\n",
    "> Qué objetos se observan en ese espacio?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6b1cac",
   "metadata": {},
   "source": [
    "## Qué es una señal de audio?\n",
    "\n",
    "+ En general, una <span style=\"color:red\">señal</span> es una descripción de cómo un `parámetro` depende de otro parámetro. Por ejemplo, en un circuito eléctrico, una señal de voltaje nos indicaría cómo ese voltaje varía con el tiempo. O en una imagen, una señal de brillo nos indicaría cómo ese brillo varía con la distancia.  \n",
    "\n",
    "+ Una señal de audio es una <span style=\"color:red\">representación del sonido</span>. \n",
    "\n",
    "+ En audio las señales pueden ser de dos tipos: \n",
    "    > - `analógicas o continuas`. \n",
    "    > - `digitales o discretas`.\n",
    "    \n",
    "+ La mayor parte de las señales de audio de la vida real (biófonos, antropófonos, geófonos) son señales que varían continuamente con el tiempo.\n",
    "\n",
    "+ Las señales discretas, en cambio, solamente existen dentro de las computadoras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a233b6",
   "metadata": {},
   "source": [
    "## Qué sensación les da la escena auditiva combinada con la escena visual? \n",
    "\n",
    "> Qué objetos sonoros se perciben en ese espacio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1349c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio1, sample_rate = torchaudio.load(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a7db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(audio1.numpy()[0], rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d3e66",
   "metadata": {},
   "source": [
    "## Representación de una señal de audio en forma de onda temporal \n",
    "\n",
    "+ El <span style=\"color:red\">eje vertical</span> representa uno de los dos parámetros de la señal. En este eje se muestra cómo cambia la `amplitud` (podría ser la variación de amplitud de la presión sonora). También, a veces, se le da el nombre de <span style=\"color:red\">variable dependiente</span>.\n",
    "\n",
    "+ El <span style=\"color:red\">eje horizontal</span> representa el segundo parámetro de la señal. Se le da también el nombre <span style=\"color:red\">variable independiente</span>. El `tiempo` suele aparecer comunmente en el eje horizontal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2171bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_functions.plot_waveform(audio1, sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5193b3d7",
   "metadata": {},
   "source": [
    "## Conversión de señal de tiempo continuo a señal de tiempo discreto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed2458",
   "metadata": {},
   "outputs": [],
   "source": [
    "_SAMPLE_DIR_IMG  = \"image_data\"\n",
    "img_path2 = os.path.join(_SAMPLE_DIR_IMG, \"c_to_d.png\")\n",
    "os.makedirs(_SAMPLE_DIR_IMG, exist_ok=True)\n",
    "display.Image(img_path2, width=\"700\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf10fab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acus099_2024",
   "language": "python",
   "name": "acus099_2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
